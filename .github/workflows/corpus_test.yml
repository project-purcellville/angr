name: Corpus Test

on:
  push:
    branches:
      - master
      - main
  pull_request:
    branches:
      - master
      - main
  workflow_dispatch:

jobs:
  fetch_binaries_metadata:
    runs-on: ubuntu-latest
    # Expose step output as job output
    outputs:
      chunks: ${{ steps.fetch_binaries.outputs.chunks }}

    steps:
      - name: Fetch binaries metadata
        id: fetch_binaries
        env:
          GITHUB_TOKEN: ${{ secrets.CORPUS_ACCESS_TOKEN }}
        run: |
          # Fetch the list of binaries from the binaries repository using the GitHub API
          fetch_files_from_tree() {
              local sha=$1
              local prefix=$2
              local response=$(curl -s -H "Authorization: token $GITHUB_TOKEN" \
                  "https://api.github.com/repos/${{ vars.CORPUS_GITHUB_OWNER }}/${{ vars.CORPUS_GITHUB_REPO }}/git/trees/${sha}?recursive=1")
              
              echo "$response" | jq -r --arg prefix "$prefix" '.tree[] | select(.type == "blob") | $prefix + "/" + .path'
          }

          # Initial path to start fetching files
          initial_path="${{ vars.CORPUS_GITHUB_PATH }}"

          # Fetch the top-level SHAs and paths
          top_level_response=$(curl -s -H "Authorization: token $GITHUB_TOKEN" \
              "https://api.github.com/repos/${{ vars.CORPUS_GITHUB_OWNER }}/${{ vars.CORPUS_GITHUB_REPO }}/contents/${initial_path}?ref=main")

              # Collect all SHAs and their corresponding paths
          sha_path_pairs=$(echo "$top_level_response" | jq -r '.[] | select(.type == "dir") | .sha + " " + .path')
          top_level_files=$(echo "$top_level_response" | jq -r '.[] | select(.type == "file") | .path')

          # Fetch files for each SHA and combine the results
          all_files=($top_level_files)
          while IFS= read -r sha_path; do
              sha=$(echo "$sha_path" | awk '{print $1}')
              path=$(echo "$sha_path" | awk '{print $2}')
              files=$(fetch_files_from_tree $sha $path)
              all_files+=($files)
          done <<< "$sha_path_pairs"

          # Count the number of files
          files_count=$(echo "${all_files[@]}" | wc -w)
          echo "Total number of files: $files_count"

          # Calculate the number of files each job should handle (max 256 jobs)
          MAX_MATRIX_JOBS=256
          CHUNK_SUFFIX_LENGTH=${#MAX_MATRIX_JOBS}
          segment_size=$((($files_count + $((MAX_MATRIX_JOBS - 1))) / MAX_MATRIX_JOBS))
          echo "Segment size (number of files per job): $segment_size"

          # Set environment variables for each chunk
          chunks=()
          current_chunk=""
          chunk_count=0

          for file in "${all_files[@]}"; do
            if [[ -n "$current_chunk" ]]; then
              current_chunk+=","
            fi
            current_chunk+="$file"
            count=$((count + 1))

            # if the segment size is reached, add chunk to array and reset
            if [[ $count -ge $segment_size ]]; then
              chunks+=("$current_chunk")
              current_chunk=""
              count=0
            fi
          done

          # Add the last chunk if it has any files
          if [[ -n "$current_chunk" ]]; then
            chunks+=("$current_chunk")
          fi

          # Output the chunks in JSON format
          echo "chunks=$(printf '%s\n' "${chunks[@]}" | jq -R -s -c 'split("\n")[:-1]')" >> "$GITHUB_OUTPUT"

  analyze_binaries:
    needs: [fetch_binaries_metadata]
    runs-on: ubuntu-latest

    strategy:
      matrix:
        chunk: ${{ fromJson(needs.fetch_binaries_metadata.outputs.chunks) }}

    steps:
      - name: Checkout current repository
        uses: actions/checkout@v3

      - name: Setup Python and Install Testing Dependencies
        uses: actions/setup-python@v5
        id: setup_python
        with:
          python-version: "3.10"
          cache: "pip"
      - name: Restore venv Cache
        uses: actions/cache/restore@v4
        with:
          key: venv-${{ runner.os }}-${{ steps.setup_python.outputs.python-version }}-${{ github.sha }}
          path: .venv
      - run: python -m venv .venv
        name: Create venv
        shell: bash
      - run: |
          source .venv/bin/activate
          pip install "setuptools>=59" wheel cffi "unicorn==2.0.1"
          pip install git+https://github.com/angr/archinfo.git
          pip install git+https://github.com/angr/pyvex.git
          pip install git+https://github.com/angr/cle.git
          pip install git+https://github.com/angr/claripy.git
          pip install git+https://github.com/angr/ailment.git
        name: Install angr Dependencies
      - run: |
          source .venv/bin/activate
          pip install --no-build-isolation .
        name: Install angr
      - run: |
          source .venv/bin/activate
          pip install pytest pytest-insta
        name: Install test frameworks

      - name: Save venv Cache
        uses: actions/cache/save@v4
        with:
          key: venv-${{ runner.os }}-${{ steps.setup_python.outputs.python-version }}-${{ github.sha }}
          path: .venv

      - name: Fetch binary files and run analysis
        env:
          GITHUB_TOKEN: ${{ secrets.CORPUS_ACCESS_TOKEN }}
        run: |
          source .venv/bin/activate

          # Determine the environment variable name for the current chunk
          files="${{ matrix.chunk }}"

          # Convert the comma-separated list of binaries into an array
          IFS=',' read -ra files_array <<< "$files"

          # Set the context to the corpus_test folder for running pytest
          cd corpus_tests

          # TODO: figure out where to pull in the old snapshots for each binary for comparison
          for file in "${files_array[@]}"; do
            if [[ -n "$file" ]]; then
              echo "Processing binary: $file"
              # Create the directory to place the downloaded files
              mkdir -p binaries/$(dirname $file)
            
              # Fetch the binary file from the binaries repository
              curl -s -H "Authorization: token $GITHUB_TOKEN" \
                -o binaries/$file \
                  "https://raw.githubusercontent.com/${{ vars.CORPUS_GITHUB_OWNER }}/${{ vars.CORPUS_GITHUB_REPO }}/main/$file"

              echo "Downloaded file $(ls binaries/$file)"

              # Attempt to fetch the snapshot if it exists
              curl -s -H "Authorization: token $GITHUB_TOKEN" \
                -o snapshots/$file \
                  "https://raw.githubusercontent.com/${{ vars.SNAPSHOT_GITHUB_OWNER }}/${{ vars.SNAPSHOT_GITHUB_REPO }}/main/$file"
                
              # Run Angr Analysis on the binary file
              pytest --insta update-new --binary binaries/$file
            fi
          done

      - name: Push snapshots to snapshot repo
        env:
          GITHUB_TOKEN: ${{ secrets.CORPUS_ACCESS_TOKEN }}
        run: |
          # Clone the snapshots repo
          git clone https://github.com/${{ vars.SNAPSHOT_GITHUB_OWNER }}/${{ vars.SNAPSHOT_GITHUB_REPO }}.git snapshots_repo
          cd snapshots_repo

          # Configure Git
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'

          # Create new PR branch
          branch_name="update-snapshots-${{ github.sha }}"
          git checkout -b $branch_name

          # TODO: use the new snapshots repository and commit the snapshot artifacts there
          git add insta_snapshots/
          git commit -m "Update decompilation snapshots"
          git push origin $branch_name

  create_pr:
    needs: [analyze_binaries]
    runs-on: ubuntu-latest

    steps:
      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ secrets.CORPUS_ACCESS_TOKEN }}
          commit-message: "Update decompilation snapshots"
          branch: update-snapshots-${{ github.sha }}
          title: "Update decompilation snapshots"
          body: "This PR updates the decompilation snapshots generated by the tool"
          head-branch: update-snapshots-${{ github.sha }}
          base: main
          repository: ${{ vars.SNAPSHOT_GITHUB_OWNER }}/${{ vars.SNAPSHOT_GITHUB_REPO }}
